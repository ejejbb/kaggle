# 1. 캐글 필사: New York Taxi Trip Duration

## 대회 소개
> 🗽 뉴욕시 택시 승차 기록 데이터를 기반으로 택시 이동 시간(trip duration)을 예측하는 문제
- 문제 유형: 회귀(Regression)
- 컬럼 설명
```
id: 고유한 식별자

vendor_id: 택시 회사 ID

pickup_datetime: 승차 시간

dropoff_datetime: 하차 시간

passenger_count: 승객 수

pickup_longitude, pickup_latitude: 승차 위치

dropoff_longitude, dropoff_latitude: 하차 위치

store_and_fwd_flag: 데이터가 즉시 전송되었는지 여부

trip_duration: 단위는 초 (target)
```
- 🔍 참가자들이 사용하는 주요 기술들
```
거리 계산: Haversine formula를 사용하여 두 지점 간 거리 계산

시간 특징 추출: 요일, 시간대 등으로 pickup_datetime을 분해

외부 데이터 활용: 날씨, 교통량 등의 정보 추가

모델: XGBoost, LightGBM, Random Forest, Neural Network 등
```

### Haversine 거리
> 지구의 곡률을 고려한 구면 거리 계산 방식

![alt text](/kaggle_study/image/image30.png)

ϕ: 위도 (radian)   
λ: 경도 (radian)   
r: 지구 반지름 (약 6371km)

## ✅ 목적
> XGBoost 모델 성능을 높이기 위한 피쳐 엔지니어링

### 데이터 이해하기
데이터 자체에 큰 오류가 없는지 확인하고, 타깃변수를 로그변환

### 피쳐 선택 - PCA
```
pickup/dropoff 좌표는 대체로 대각선 방향(↘, ↖)으로 분포되어 있음.

트리 모델은 수직( | ) 또는 수평(—) 기준으로 나누기 때문에, 대각선으로 퍼진 데이터를 잘 자르려면 여러 split이 필요함 (비효율)

👉 PCA로 축을 회전시켜 대각선을 x축 정렬처럼 바꿔주면 →
트리 모델이 단순한 조건으로 나눌 수 있음
```
#### 거리
`haversine 거리`를 이용해 계산

#### 평균 속도
시간대별 평균 속도
![alt text](/kaggle_study/image/image31.png)

지역별 평균 속도
![alt text](/kaggle_study/image/image32.png)

#### 클러스터링
```python
sample_ind = np.random.permutation(len(coords))[:500000] ## 무작위로 50만 개 좌표 샘플 추출

kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])
# MiniBatchKMeans: 일반 KMeans보다 빠르게 동작하는 대용량 최적화 버전
# n_clusters=100: 총 100개의 지역 구역으로 나눔
## 소수점 3자리 기준 좌표로 나누면 약 100~200개의 클러스터가 적절한 해상도를 가진다고 한다.
## 100개 정도는 LightGBM, XGBoost, CatBoost 등 트리 기반 모델에서 잘 처리 가능한 범위
```
![alt text](/kaggle_study/image/image33.png)

#### 파생변수 생성

##### 단일 컬럼 기준

컬럼명 | 이유
|---|---|
pickup_hour | 시간대(러시아워 등)에 따라 교통 혼잡도 차이 반영
pickup_date | 특정 날짜 이슈 (눈, 비, 공휴일 등)
pickup_week_hour | 요일 + 시간 조합 (예: 수요일 아침 8시)
pickup_dt_bin | 3시간 단위 시간 구간 (좀 더 일반적인 시간 흐름 파악)
pickup_cluster / dropoff_cluster | 위치 기반 군집 → 지역별 교통 특성 반영

##### 다중 컬럼 기준
조합 컬럼 | 이유
|---|---|
center_lat_bin + center_long_bin | 중심 좌표 단위로 공간 통계 (ex. 평균 속도)
pickup_hour + center_lat_bin + center_long_bin | 특정 시간 + 지역의 교통 패턴
pickup_hour + pickup_cluster | 군집 + 시간대별 속도
pickup_cluster + dropoff_cluster | 이동 경로(출발~도착 조합)별 평균 시간/속도

##### 수요 예측 피쳐 생성
 단계 | 설명
 |---|---|
 pickup_datetime_group | 모든 픽업 시간을 60분 단위로 반올림하여 그룹핑 기준 생성
 count_60min | 시간 흐름에 따라 전체 트립 수를 계산 (수요의 흐름)
 dropoff_cluster_count | 각 드롭오프 클러스터별 4시간 이동 평균 수요 계산 후, 2시간 앞당겨서 예측용 피쳐 생성
 pickup_cluster_count | 각 픽업 클러스터별도 동일하게 4시간 평균 수요 계산 후 2시간 앞당겨서 예측용 피쳐 생성

 ❓ 왜 4시간 이동평균을 계산하고 2시간 앞당길까?   
 > 1. **왜 4시간 이동 평균?을 한걸까**
- 시계열 데이터는 순간적인 값보다 트렌드가 중요하다.
- 단일 시간대 수요만 보면 **너무 불안정**해서 예측력이 떨어질 수 있다.
- 최근 4시간 트렌드는 앞으로 1~2시간을 예측하기에 적절하다.
> 2. **왜 2시간을 앞당긴걸까**
- 이동 평균은 **현재 시점을 포함한 과거 데이터를 기반**으로 계산된다.
- 그런데 이걸 **그대로 현재 시점 피처로 쓰면 → 미래를 본 것과 같은 효과**가 되어버린다.
- 예측 모델은 **현재 시점 이전의 정보만 이용해야** 하므로, **이 수요는 2시간 전에 알 수 있었던 정보다**라고 모델에게 알려주는 것.
- 정보 누수를 막기 위함

> **3. 예시**

시각 (t) | 실제 수요 | 과거 4시간 평균 (rolling(4h)) | shift(-2h) 적용 시 사용되는 시각
|--|--|--|--|
06:00 | 80 | (없음) – 4시간 미만 | -
07:00 | 100 | (없음) – 4시간 미만 | -
08:00 | 90 | (없음) – 4시간 미만 | -
09:00 | 110 | (80+100+90+110)/4 = 95.0 | 07:00 시점에 사용됨
10:00 | 130 | (100+90+110+130)/4 = 107.5 | 08:00 시점에 사용됨
11:00 | 120 | (90+110+130+120)/4 = 112.5 | 09:00 시점에 사용됨
12:00 | 140 | (110+130+120+140)/4 = 125.0 | 10:00 시점에 사용됨
13:00 | 160 | (130+120+140+160)/4 = 137.5 | 11:00 시점에 사용됨

```
10시의 이동평균 정보를 8시에 예측할 때 사용하려는 것이 아니라 그 값을 10시에 쓰이지 않게 옮겨 놓은 것일 뿐
```

#### OSRM 피처
```
oscarleo라는 사람이 OSRM을 사용해서 직접 계산한 경로 기반 거리/시간 정보라고 한다.
현재는 아쉽게도 private 처리되어 불러올 수 없다.

이 이후에 모델링을 하는 과정에서 osrm 피처를 이용해서 하기 때문에 결과를 실행할 수는 없었다.
```
예측에 특별한 영향을 주지 않는 컬럼 삭제
```python
do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime',                      'trip_duration', 'check_trip_duration',
'pickup_date', 'avg_speed_h', 'avg_speed_m',
'pickup_lat_bin', 'pickup_long_bin',
'center_lat_bin', 'center_long_bin',
'pickup_dt_bin', 'pickup_datetime_group']
```
```
id, 날짜: 식별자/시간 정보 → 예측에 의미 없음

trip_duration, log_trip_duration: 타겟 값이므로 피처로 사용하면 안 됨

_bin, _dt_bin: 중간 단계 피처로 분석에는 썼지만 학습에는 제외
```

#### 모델링 전 피쳐 체크
일반적으로 Kaggle 대회에서는 **train과 test 데이터가 iid 분포**를 가지지만, 만약 train과 test 세트 간에 특정 피처의 분포 차이가 매우 크다면 대부분의 경우 피처 엔지니어링 파이프라인에 오류가 있을 가능성이 높기 때문에 미리 분포를 확인하는 것이 중요하다.


#### 모델링
XGBoost는 하이퍼파라미터를 어떻게 설정하느냐에 따라 성능차이가 매우 크다.

```python
xgb_pars = {
    'min_child_weight': 50,
    'eta': 0.3,
    'colsample_bytree': 0.3,
    'max_depth': 10,
    'subsample': 0.8,
    'lambda': 1.,
    'nthread': 4,
    'booster': 'gbtree',
    'silent': 1,
    'eval_metric': 'rmse',
    'objective': 'reg:linear'
}
```
파라미터 | 설명 | 추천 값 범위
|---|---|---|
min_child_weight | 하나의 리프 노드가 최소로 가져야 할 가중치 합값이 클수록 과적합 방지됨 | 1 ~ 50
eta | 학습률 (learning rate)값이 작을수록 학습이 느리지만 더 정교 | 0.01 ~ 0.3
colsample_bytree | 트리 생성 시 샘플링할 피처 비율과적합 방지 효과 | 0.3 ~ 1.0
max_depth | 각 트리의 최대 깊이클수록 복잡한 모델, 과적합 위험 증가 | 3 ~ 10
subsample | 각 트리 생성 시 샘플링할 데이터의 비율 | 0.5 ~ 1.0
lambda | L2 정규화 항 (가중치의 제곱에 패널티) | 0 ~ 10
nthread | 학습 시 사용할 CPU 쓰레드 수 | 시스템에 맞게 설정
booster | 사용할 부스터 종류보통 gbtree (트리 기반) 사용 | 'gbtree', 'gblinear', 'dart'
silent | 로깅 여부 (1: 조용하게) ← 현재는 deprecated | 0 or 1 (→ 최신버전에서는 제거됨)
eval_metric | 평가 지표 (여기선 rmse 사용) | 'rmse', 'mae', 'logloss' 등
objective | 문제의 종류 지정회귀 문제라 reg:linear 사용 | reg:squarederror ← 최신 추천

목표 | 중요 파라미터
|---|---|
과적합 줄이기 | max_depth, min_child_weight, subsample, colsample_bytree, lambda
성능 올리기 | eta (작게), 트리 수 증가 (num_boost_round)
빠른 결과 | eta=0.3, max_depth=6 등으로 빠르게 돌려보기


**모델 학습시키기**
```python
model = xgb.train(
    xgb_pars,              # 하이퍼파라미터 설정 딕셔너리
    dtrain,                # 학습 데이터 (DMatrix 형식)
    60,                    # 최대 boosting round 수 (트리 최대 60개까지 생성)
    watchlist,             # 성능 모니터링용 train/valid 데이터
    early_stopping_rounds=50,  # 검증 성능이 50 라운드 동안 좋아지지 않으면 학습 중단
    maximize=False,        # 평가 지표(RMSE)는 작을수록 좋기 때문에 False
    verbose_eval=10        # 10라운드마다 학습 로그 출력
)
```

#### 피처 중요도 분석
![alt text](/kaggle_study/image/image34.png)

```
점수가 높다는 것은 트리에서 더 자주 분할(split)에 사용되었다는 의미일 뿐, 해당 피쳐가 정말 중요한 것은 아닐 수 있다는 점을 유의해야 한다.

피처 간 강한 상관관계나, 고유값 수가 많은 피처가 있을 경우 결과가 왜곡될 수 있다.
```

XGBoost의 피처 중요도(feature importance)와 피처 제거 시 RMSE 변화량을 시각화   
![alt text](/kaggle_study/image/image35.png)

예측이 잘 되었는지 시각화   
![alt text](/kaggle_study/image/image36.png)   
대부분 예측이 잘 되었으나 이상치는 예측이 어려움.