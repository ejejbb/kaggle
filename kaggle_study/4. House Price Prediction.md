# 1. 캐글 필사: House Price Prediction

## 대회 소개
> 🏡 아이오와주 Ames의 주택 데이터를 기반으로 주택 판매 가격(SalePrice)을 예측하는 회귀 문제

* 컬럼 설명 (총 79개의 설명 변수 포함)
```
Id: 각 행을 구분하는 고유 ID  
SalePrice: 주택 판매 가격 (Target)  
LotArea: 부지 면적  
OverallQual: 전반적인 자재 및 마감 품질  
YearBuilt: 주택이 건축된 연도  
GrLivArea: 지상 생활 공간 면적  
GarageCars: 차고 수용 차량 수  
... (다양한 구조적, 위치적, 품질 관련 변수 포함)
```

* 📊 평가 지표: RMSE
```
평가 시 예측값과 실제값의 **로그 값 차이**를 기반으로 RMSE 계산
→ 고가/저가 주택 모두 동일한 비중으로 오차 측정
```

* 🔍 참가자들이 사용하는 주요 기술들
```
피처 엔지니어링: 범주형 변수 처리, 결측값 처리, 변수 변환(로그, Box-Cox 등)

회귀 모델링:  
  - 선형 회귀 (Linear, Ridge, Lasso, ElasticNet)  
  - 트리 기반 모델 (Random Forest, Gradient Boosting, XGBoost, LightGBM)  
  - 앙상블(Stacking, Blending, Voting 등)  
EDA: 변수 간 상관관계 분석, 분포 시각화, 이상치 탐지 등  
```

### 데이터 불러오기
```python
house_df = pd.concat([train,X_test],ignore_index = True, sort = False) # train과 test 데이터를 합침
tr_idx = house_df['SalePrice'].notnull()
```

### 유용한 함수 정의
> PCA

```python
def apply_pca(X, standardize=True):
    # Standardize - pca는 스케일의 영향을 많이 받으므로
    if standardize:
        X = (X - X.mean(axis=0)) / X.std(axis=0)
    # Create principal components
    pca = PCA()
    X_pca = pca.fit_transform(X)
    # Convert to dataframe - 각 주성분에 이름 부여 후 dataframe으로 변환
    component_names = [f"PC{i+1}" for i in range(X_pca.shape[1])]
    X_pca = pd.DataFrame(X_pca, columns=component_names)
    # Create loadings - 각 주성분의 피쳐별 기여도(로딩) 행렬
    loadings = pd.DataFrame(
        pca.components_.T,  # transpose the matrix of loadings
        columns=component_names,  # so the columns are the principal components
        index=X.columns,  # and the rows are the original features
    )
    return pca, X_pca, loadings
```

### 결측치 보간
> 수치형 - KNN 사용

KNN Imputer는 결측치가 있는 행을 비슷한 다른 행들의 값 평균으로 채우는 방식
```
각 샘플(행)의 결측값은 가장 가까운 이웃 n개의 평균값을 사용해서 채워진다.

두 샘플이 "가깝다"고 판단되는 기준은, 서로 공통적으로 결측치가 없는 피처들의 값이 비슷할 경우다.

즉, 사용 가능한 값만을 기준으로 거리(유사도)를 측정하고, 그 기반으로 이웃을 결정해 평균을 내는 방식이다.
```

회귀 문제에서는 값들이 연속적이므로, 단순한 평균이나 중앙값보다 KNN을 이용한 유사도 기반 평균이 더 자연스럽고 성능이 높을 수 있다.

### 타깃 변수의 시각화
![alt text](/kaggle_study/image/image37.png)

로그 변환 후,   
![alt text](/kaggle_study/image/image38.png)

로그 함수는 작은 숫자 간의 간격은 넓히고, 큰 숫자 간의 간격은 줄여주는 성질이 있음.

### prophet을 이용해 타깃 변수 예측하기
1. Prophet   
: Meta(구 페이스북)에서 만든 시계열 데이터 예측 라이브러리로, 트렌드·계절성·휴일 효과 등을 자동으로 감지해주는 모델   

2. *YearBuilt*와 *YearRemodAdd*를 사용
> 최근일수록, 최근에 리모델링을 했을수록 값이 높아짐

![alt text](/kaggle_study/image/image39.png)

![alt text](/kaggle_study/image/image40.png)

### 이상치 확인 및 제거
```python
sns.set(font_scale = 1.5)
sns.set_style("white")
sns.set_palette("Blues_r")
plt.figure(figsize=(16,5))
plt.subplot(1,2,1)
plt.subplots_adjust(wspace=0.3)
ax1 = sns.regplot(data=house_df, x='GrLivArea',y='SalePrice')
ax1.set_title('Outliers in GrLivArea',fontsize=20)
plt.axhline(y=250000, color='Green', linestyle='--', linewidth=3)
plt.axvline(x=4000, color='Green', linestyle='--', linewidth=3)
plt.text(4500, 150000, 'Outliers',color='red')
plt.subplot(1,2,2)
ax2 = sns.regplot(data=house_df, x='TotalBsmtSF',y='SalePrice')
ax2.set_title('Outliers in TotalBsmtSF',fontsize=20)
plt.axhline(y=250000, color='Green', linestyle='--', linewidth=3)
plt.axvline(x=4500, color='Green', linestyle='--', linewidth=3)
plt.text(5000, 200000, 'Outliers',color='red')
sns.despine()
```

이상치 판별 기준을 통계적으로 정한 것이 아니라 `도메인 지식 + 시각적 판단`으로 결정한 것.

ex. 일반적인 주택 면적(GrLivArea)은 대략 1500~2500 sq.ft 정도이므로 4000 sq.ft는 미국 평균 가정의 2배 이상인 것이므로 이상치로 판단.