# 1. 캐글 필사: PetFinder.my - Pawpularity Contest

## 🐶 대회 소개
> 유기 동물 입양 플랫폼 PetFinder.my의 반려동물 프로필 이미지를 기반으로 **Pawpularity 점수(인기도)** 를 예측하는 회귀 문제

* Pawpularity는 사진의 **웹/모바일 페이지 조회 수**, 클릭, 스크롤 등의 사용자 반응을 기반으로 계산되며, **다양한 환경 요인을 보정한 정규화된 지표**.

## 🐾 대회 목적
> **AI 기반 추천 시스템**을 구축해 보호소 사진의 **품질 개선**과 **구도 추천**을 제공하고, 더 많은 유기동물이 빠르게 입양될 수 있도록 돕는 것을 목표로 함.

---

## 📁 데이터 구성
> 이미지 데이터 + 수작업으로 라벨링된 메타데이터 제공
```
🔸 이미지 데이터

* `train/`: `{id}.jpg` 형식의 훈련 이미지 (약 9,900개)
* `test/`: 테스트 이미지 (약 6,800개, 평가 시 실제 데이터로 교체됨)

🔸 메타데이터 (CSV)

* `train.csv`: 훈련 이미지에 대한 메타데이터 + 목표값 `Pawpularity` 포함
* `test.csv`: 테스트 이미지용 메타데이터
* `sample_submission.csv`: 제출 예시 파일 (Id, 예측 Pawpularity 포함)
```
---

### 📌 주요 컬럼 (train.csv / test.csv 공통)

```
Id           : 이미지 파일명과 동일한 고유 ID
Pawpularity  : (train에만 있음) 예측 대상 인기도 점수 (0~100 사이)
Focus        : 배경이 깔끔하고 피사체(동물)가 잘 드러나는지
Eyes         : 눈이 정면 또는 거의 정면을 향하고 명확한지
Face         : 얼굴이 명확하게 보이는지
Near         : 한 마리의 동물이 사진의 절반 이상을 차지하는지
Action       : 동작이 담겨 있는지 (예: 점프)
Accessory    : 장난감, 스티커 등 소품이 있는지
Group        : 여러 마리 동물이 함께 있는지
Collage      : 콜라주 이미지인지
Human        : 사람이 사진에 있는지
Occlusion    : 장애물(우리, 손 등)이 동물을 가리는지
Info         : 텍스트/라벨이 이미지에 있는지
Blur         : 흐릿하거나 노이즈가 있는지 (Eyes가 0으로 고정됨)
```

---

## 📊 평가 지표: RMSE
>예측한 Pawpularity 점수와 실제 점수 간의 제곱 오차 평균의 제곱근
```
RMSE = sqrt(mean((y_pred - y_true)^2))

→ 고득점과 저득점 모두에 동일한 중요도를 부여함
```

---

## 🧠 참가자들이 사용하는 주요 기술들

```
🔍 EDA:
- 메타데이터와 Pawpularity 간의 상관관계 시각화
- 이미지 밝기, 색상, 해상도 등 이미지 통계값 추출

🛠 피처 엔지니어링:
- 메타데이터 기반 변수 선택 / 조합
- 이미지 기반 추가 피처 생성 (CNN 중간 출력, 이미지 통계)

📷 딥러닝 모델링:
- 이미지 전용 모델: fastai, timm, EfficientNet, Swin Transformer
- 이미지 + 메타데이터 혼합 모델 (TabNet, MLP + CNN 병렬 구조)

🧪 앙상블:
- K-fold cross-validation
- 모델 앙상블 / 블렌딩
```

---

### 데이터 불러오기
```python
from google.colab import files
files.upload()
## 다운받은 token 파일을 업로드

# Kaggle API 설치 및 설정
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# 대회 데이터 다운로드
## 대회 참가해야 데이터 다운 가능
!kaggle competitions download -c petfinder-pawpularity-score

# 압축 해제
!unzip -q -o petfinder-pawpularity-score.zip

# 데이터 로드
import pandas as pd

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
sample_submission = pd.read_csv('sample_submission.csv')
```

### 필요한 모듈 불러오기
> timm, fastai

#### 1. `timm` (PyTorch Image Models)

> 수많은 최신 이미지 분류 모델들을 빠르게 불러올 수 있는 PyTorch 기반 라이브러리

✅ 특징

* **사전학습된(pretrained)** 모델 수백 개 내장 (ResNet, EfficientNet, Swin Transformer, ConvNeXt 등)
* `create_model()` 한 줄로 불러오기 가능
* 다양한 모델 구조와 head 설정(분류, 회귀, feature extractor 등) 지원
* PyTorch 기반이라 **유연성** 높고, 연구용/실전 모두에 적합
* 이미지 분류, **이미지 회귀**, Transfer learning, Fine-tuning 등에 사용

#### 2. `fastai`
> 딥러닝 실험을 빠르고 쉽게 할 수 있게 만든 고수준 PyTorch wrapper 라이브러리

✅ 특징

* `DataBlock`, `Learner`, `cnn_learner` 같은 고수준 API 제공
* **자동 학습률 탐색**, **전처리/증강**, **콜백**, **모델 평가** 등 실전 기능 다수 포함
* tabular, vision, NLP, audio 등 다양한 도메인 지원
* 모델 학습 과정을 간단히 구성하고 빠르게 반복 실험 가능
* 이미지 분류/회귀, 텍스트 분류, 감성 분석, 표 데이터 회귀/분류, Rapid prototyping 등에 사용

---

| 라이브러리    | 주요 기능         | 활용 목적              |
| -------- | ------------- | ------------------ |
| `timm`   | 다양한 이미지 모델 제공 | 모델 아키텍처 선택         |
| `fastai` | 학습 파이프라인 구성   | 빠른 실험, 전체 워크플로우 통합 |



### 이미지 데이터 로드
> fastai 라이브러리의 `ImageDataLoaders.from_df()`를 사용해서 Pawpularity 대회의 데이터를 학습용 DataLoaders 객체로 변환

```python
dls = ImageDataLoaders.from_df(train, #pass in train DataFrame
                               valid_pct=0.2, #80-20 train-validation random split
                               seed=999, #seed 고정
                               fn_col='path', #filename/path is in the second column of the DataFrame
                               label_col='norm_score', #label is in the first column of the DataFrame(target)
                               y_block=RegressionBlock, #The type of target(회귀문제)
                               bs=32, #pass in batch size(한 번에 모델에 들어갈 샘플 수)
                               num_workers=8, # 데이터 로딩 시 동시에 작업할 프로세스 수
                               item_tfms=Resize(224), #각 이미지를 224×224 크기로 리사이즈(모델 입력에 맞추기 위한 전처리)
                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #배치 단위 증강

dls.show_batch() ## 한 배치를 시각화해서 확인
```
![alt text](/kaggle_study/image/image42.png)

### 모델 훈련

```python
# define model
model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=dls.c)

## `pretrained=True` → 사전학습된 ImageNet-1K 가중치 사용
## `num_classes=dls.c` → fastai의 DataLoaders(dls)로부터 타깃 출력 수 자동 설정 (회귀면 1, 분류면 클래스 수)
```

```python
# 평가지표 정의
def petfinder_rmse(input, target):
    return 100 * torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))
```
예를 들어, 모델이 `input = [2.3, 1.5]`를 출력하고,
실제 `target = [0.83, 0.65]` 라면:

```python
sigmoid([2.3, 1.5]) ≈ [0.908, 0.818]
# sigmoid는 로짓값을 0~1 사이로 정규화
→ MSE = ((0.908 - 0.83)^2 + (0.818 - 0.65)^2)/2 ≈ 0.012
→ RMSE = sqrt(0.012) ≈ 0.11
→ 반환값 = 0.11 * 100 = 11
```
